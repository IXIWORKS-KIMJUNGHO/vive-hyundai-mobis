#!/usr/bin/env python3
"""
Unified Face Analyzer TCP Server
í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ì´ë¯¸ì§€ë¥¼ ìˆ˜ì‹ í•˜ì—¬ ì‹¤ì‹œê°„ ì–¼êµ´ ë¶„ì„ ìˆ˜í–‰

âš ï¸ ì£¼ì˜: ì´ íŒŒì¼ì€ camera_client_python.pyì™€ ë‹¤ë¥¸ ì—­í• ì…ë‹ˆë‹¤!
- tcp_server.py: ì–¼êµ´ ë¶„ì„ ì„œë¹„ìŠ¤ ì œê³µ (ì„œë²„ ì—­í• , Port 10000)
- camera_client_python.py: IR Cameraì—ì„œ Raw Y8 ìˆ˜ì‹  (í´ë¼ì´ì–¸íŠ¸ ì—­í• , Port 5001)

Protocol:
1. Client â†’ Server: ì´ë¯¸ì§€ ë°ì´í„° (JPEG/PNG/Raw Y8 ìë™ ê°ì§€)
2. Server: UnifiedFaceAnalyzerë¡œ ë¶„ì„
3. Server â†’ Client: JSON ë¶„ì„ ê²°ê³¼ (TCP_SPEC í˜•ì‹)

ì§€ì› ì´ë¯¸ì§€ í˜•ì‹:
- JPEG (ì‹œê·¸ë‹ˆì²˜ ê°ì§€)
- PNG (ì‹œê·¸ë‹ˆì²˜ ê°ì§€)
- Raw Y8 (í¬ê¸° ê¸°ë°˜ ê°ì§€: 1280x800, 1280x720, 1920x1080)

Port: 10000 (default)
"""

import socket
import json
import logging
from typing import Optional, Dict, Any
from io import BytesIO
from PIL import Image
import numpy as np
import cv2
import time

from core.unified_analyzer import UnifiedFaceAnalyzer
from utils import get_logger

logger = get_logger(__name__)


class UnifiedFaceAnalysisTCPServer:
    """
    í†µí•© ì–¼êµ´ ë¶„ì„ TCP ì„œë²„

    Features:
    - Raw ì´ë¯¸ì§€ ë°ì´í„° ìˆ˜ì‹  (Unreal Engine)
    - UnifiedFaceAnalyzerë¡œ ë¶„ì„
    - JSON ê²°ê³¼ ì „ì†¡
    """

    # Enum ë§¤í•‘ (TCP_SPEC.md ê·œê²©)
    HAIRSTYLE_ENUM = {
        "Bangs": 0,
        "All-Back": 1,
        "Center Part": 2,
        "Right Side Part": 3,
        "Left Side Part": 4,
        "Short Hair": 5,
        "Long Hair": 6,
    }

    GENDER_ENUM = {
        "Female": 0,
        "Male": 1,
    }

    FACE_SHAPE_ENUM = {
        "oval": 0,   # ê³„ë€í˜•
        "round": 1,  # ë‘¥ê·¼í˜•
    }

    EYE_SHAPE_ENUM = {
        "upturned": 0,    # ì˜¬ë¼ê°„ ëˆˆ
        "downturned": 1,  # ë‚´ë ¤ê°„ ëˆˆ
        "neutral": 2,     # ê¸°ë³¸í˜•
    }

    def __init__(
        self,
        host: str = '0.0.0.0',
        port: int = 10000,
        max_connections: int = 5
    ):
        """
        TCP ì„œë²„ ì´ˆê¸°í™”

        Args:
            host: ì„œë²„ ì£¼ì†Œ (ê¸°ë³¸: 0.0.0.0 - ëª¨ë“  ì¸í„°í˜ì´ìŠ¤)
            port: í¬íŠ¸ ë²ˆí˜¸ (ê¸°ë³¸: 5000)
            max_connections: ìµœëŒ€ ë™ì‹œ ì—°ê²° ìˆ˜
        """
        self.host = host
        self.port = port
        self.max_connections = max_connections

        self.server_socket: Optional[socket.socket] = None
        self.is_running = False

        # UnifiedFaceAnalyzer ì´ˆê¸°í™”
        print("ğŸ”§ UnifiedFaceAnalyzer ì´ˆê¸°í™” ì¤‘...")
        self.analyzer = UnifiedFaceAnalyzer()
        print("âœ… ì´ˆê¸°í™” ì™„ë£Œ\n")

    def start(self):
        """ì„œë²„ ì‹œì‘"""
        try:
            # ì†Œì¼“ ìƒì„±
            self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)

            # ì†Œì¼“ ì˜µì…˜ ì„¤ì • (ì£¼ì†Œ ì¬ì‚¬ìš© í—ˆìš©)
            self.server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

            # ë°”ì¸ë”©
            self.server_socket.bind((self.host, self.port))

            # ë¦¬ìŠ¤ë‹
            self.server_socket.listen(self.max_connections)

            self.is_running = True

            print("=" * 80)
            print("  Unified Face Analysis TCP Server")
            print("=" * 80)
            print(f"âœ… TCP ì„œë²„ ì‹œì‘: {self.host}:{self.port}")
            print(f"ğŸ“¡ ì—°ê²° ëŒ€ê¸° ì¤‘... (ìµœëŒ€ {self.max_connections}ê°œ ì—°ê²°)")
            print(f"ğŸ¯ ë¶„ì„ ëª¨ë“ˆ: MediaPipe + Hairstyle + Eye Shape + Face Shape")
            print("=" * 80)
            print()

            logger.info(f"TCP server started on {self.host}:{self.port}")

        except Exception as e:
            logger.error(f"Failed to start server: {e}")
            print(f"âŒ ì„œë²„ ì‹œì‘ ì‹¤íŒ¨: {e}")
            raise

    def stop(self):
        """ì„œë²„ ì¢…ë£Œ"""
        self.is_running = False
        if self.server_socket:
            self.server_socket.close()
            logger.info("TCP server stopped")
            print("\nâœ… TCP ì„œë²„ ì¢…ë£Œ")

    def _detect_image_format(self, data: bytes) -> str:
        """
        ì´ë¯¸ì§€ ë°ì´í„° í˜•ì‹ ìë™ ê°ì§€

        Args:
            data: ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ ë°ì´í„°

        Returns:
            'png', 'jpeg', 'raw_y8', ë˜ëŠ” 'unknown'
        """
        if len(data) < 8:
            return 'unknown'

        # PNG ì‹œê·¸ë‹ˆì²˜: 89 50 4E 47 0D 0A 1A 0A
        if data[:8] == b'\x89PNG\r\n\x1a\n':
            return 'png'

        # JPEG ì‹œê·¸ë‹ˆì²˜: FF D8 FF
        if data[:3] == b'\xff\xd8\xff':
            return 'jpeg'

        # Raw Y8 ì¶”ì • (ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ê°€ ì•„ë‹Œ ê²½ìš°)
        # ì¼ë°˜ì ìœ¼ë¡œ 1280x800 = 1,024,000 bytes
        if len(data) in [1024000, 921600, 2073600]:  # 1280x800, 1280x720, 1920x1080
            return 'raw_y8'

        return 'unknown'

    def _decode_raw_y8(self, data: bytes, width: int = 1280, height: int = 800) -> Optional[np.ndarray]:
        """
        Raw Y8 ë°ì´í„°ë¥¼ BGR ì´ë¯¸ì§€ë¡œ ë³€í™˜

        Args:
            data: Raw Y8 ë°”ì´ë„ˆë¦¬ ë°ì´í„°
            width: ì´ë¯¸ì§€ ë„ˆë¹„
            height: ì´ë¯¸ì§€ ë†’ì´

        Returns:
            numpy array (BGR í¬ë§·) ë˜ëŠ” None
        """
        try:
            expected_size = width * height

            if len(data) != expected_size:
                logger.warning(f"Y8 data size mismatch: expected {expected_size}, got {len(data)}")
                # ì¼ë°˜ì ì¸ í•´ìƒë„ë¡œ ì¬ì‹œë„
                common_resolutions = [
                    (1280, 800),
                    (1280, 720),
                    (1920, 1080),
                    (640, 480)
                ]
                for w, h in common_resolutions:
                    if len(data) == w * h:
                        width, height = w, h
                        logger.info(f"Auto-detected resolution: {width}x{height}")
                        break
                else:
                    logger.error("Cannot determine Y8 image resolution")
                    return None

            # Y8 ë°°ì—´ë¡œ ë³€í™˜
            y8_array = np.frombuffer(data, dtype=np.uint8)

            # 2D ë°°ì—´ë¡œ reshape
            y8_image = y8_array.reshape((height, width))

            # Grayscale â†’ BGR ë³€í™˜
            bgr_image = cv2.cvtColor(y8_image, cv2.COLOR_GRAY2BGR)

            logger.info(f"Raw Y8 decoded: {bgr_image.shape}")
            return bgr_image

        except Exception as e:
            logger.error(f"Error decoding raw Y8: {e}")
            return None

    def receive_image(self, client_socket: socket.socket, buffer_size: int = 1024000) -> Optional[np.ndarray]:
        """
        í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ì´ë¯¸ì§€ ë°ì´í„° ìˆ˜ì‹  (ìë™ í˜•ì‹ ê°ì§€)

        Protocol (No size header):
        - ì§ì ‘ raw ë°ì´í„° ìˆ˜ì‹  (JPEG/PNG/Raw Y8)
        - ì²« ë²ˆì§¸ ì²­í¬ì—ì„œ í˜•ì‹ ìë™ ê°ì§€

        Args:
            client_socket: í´ë¼ì´ì–¸íŠ¸ ì†Œì¼“
            buffer_size: ìˆ˜ì‹  ë²„í¼ í¬ê¸° (ê¸°ë³¸: 1024000 = 1280x800 Y8)

        Returns:
            numpy array (BGR í¬ë§·) ë˜ëŠ” None
        """
        try:
            # 1. ì²« ë²ˆì§¸ ì²­í¬ ìˆ˜ì‹  (í˜•ì‹ ê°ì§€ìš©)
            logger.info(f"Waiting to receive image data (buffer_size: {buffer_size})...")
            first_chunk = client_socket.recv(buffer_size)

            if not first_chunk:
                logger.warning("No data received")
                return None

            logger.info(f"Received {len(first_chunk)} bytes")

            # ë””ë²„ê·¸: ì²« 16 bytes hex dump
            hex_preview = ' '.join(f'{b:02x}' for b in first_chunk[:16])
            logger.info(f"First 16 bytes (hex): {hex_preview}")

            # 2. ì´ë¯¸ì§€ í˜•ì‹ ìë™ ê°ì§€
            image_format = self._detect_image_format(first_chunk)
            logger.info(f"Detected image format: {image_format}")

            # 3. Raw Y8ì¸ ê²½ìš° ì •í™•í•œ í¬ê¸°ë¡œ ìˆ˜ì‹ 
            if image_format == 'raw_y8':
                expected_size = len(first_chunk)
                logger.info(f"Raw Y8 detected, received size: {expected_size}")

                # ì¼ë°˜ì ì¸ Y8 í¬ê¸° í™•ì¸
                if expected_size not in [1024000, 921600, 2073600]:
                    # í¬ê¸°ê°€ ì •í™•í•˜ì§€ ì•Šìœ¼ë©´ ë” ìˆ˜ì‹  í•„ìš”
                    logger.warning(f"Unexpected Y8 size: {expected_size}, trying to receive more")
                    image_data = first_chunk
                    while len(image_data) < buffer_size:
                        chunk = client_socket.recv(buffer_size - len(image_data))
                        if not chunk:
                            break
                        image_data += chunk
                    logger.info(f"After additional recv: {len(image_data)} bytes total")
                else:
                    image_data = first_chunk
                    logger.info(f"Y8 size is valid: {expected_size} bytes")

                # Raw Y8 ë””ì½”ë”©
                logger.info(f"Decoding Y8 data: {len(image_data)} bytes")
                image = self._decode_raw_y8(image_data)

                if image is not None:
                    logger.info(f"Y8 decoding successful: {image.shape}")
                else:
                    logger.error("Y8 decoding failed")

            elif image_format in ['png', 'jpeg']:
                # ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ëŠ” ë” ë§ì€ ë°ì´í„° ìˆ˜ì‹  í•„ìš”í•  ìˆ˜ ìˆìŒ
                image_data = first_chunk

                # PNG/JPEGëŠ” ì „ì²´ ë°ì´í„°ê°€ í•„ìš” (ì¼ë°˜ì ìœ¼ë¡œ ì²« ì²­í¬ì— í¬í•¨ë˜ì§€ë§Œ í° ê²½ìš° ì¶”ê°€ ìˆ˜ì‹ )
                # íƒ€ì„ì•„ì›ƒ ì„¤ì •ìœ¼ë¡œ ì¶”ê°€ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¤‘ë‹¨
                client_socket.settimeout(0.1)  # 100ms timeout
                try:
                    while True:
                        chunk = client_socket.recv(65536)
                        if not chunk:
                            break
                        image_data += chunk
                except socket.timeout:
                    # íƒ€ì„ì•„ì›ƒì€ ì •ìƒ (ë” ì´ìƒ ë°ì´í„° ì—†ìŒ)
                    pass
                finally:
                    client_socket.settimeout(None)  # íƒ€ì„ì•„ì›ƒ í•´ì œ

                # ì´ë¯¸ì§€ ë””ì½”ë”©
                image_array = np.frombuffer(image_data, dtype=np.uint8)
                image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)

            else:
                logger.warning(f"Unknown image format, trying standard decode...")
                image_data = first_chunk

                # Fallback: ì¼ë°˜ ë””ì½”ë”© ì‹œë„
                image_array = np.frombuffer(image_data, dtype=np.uint8)
                image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)

                # ë””ì½”ë”© ì‹¤íŒ¨ ì‹œ Raw Y8ë¡œ ì¬ì‹œë„
                if image is None:
                    logger.info("Standard decode failed, trying raw Y8...")
                    image = self._decode_raw_y8(image_data)

            if image is None:
                logger.error("Failed to decode image")
                return None

            logger.info(f"Image received: {image.shape}")
            return image

        except Exception as e:
            logger.error(f"Error receiving image: {e}")
            return None

    def _sanitize_for_json(self, obj):
        """
        JSON ì§ë ¬í™”ê°€ ë¶ˆê°€ëŠ¥í•œ ê°ì²´ë¥¼ ì œê±°/ë³€í™˜

        Args:
            obj: ì •ë¦¬í•  ê°ì²´

        Returns:
            JSON ì§ë ¬í™” ê°€ëŠ¥í•œ ê°ì²´
        """
        try:
            import dlib
            has_dlib = True
        except ImportError:
            has_dlib = False

        if isinstance(obj, dict):
            result = {}
            for k, v in obj.items():
                sanitized = self._sanitize_for_json(v)
                if sanitized is not None:
                    result[k] = sanitized
            return result
        elif isinstance(obj, list):
            return [self._sanitize_for_json(item) for item in obj if self._sanitize_for_json(item) is not None]
        elif isinstance(obj, tuple):
            return [self._sanitize_for_json(item) for item in obj if self._sanitize_for_json(item) is not None]
        elif isinstance(obj, np.ndarray):
            # numpy arrayëŠ” ì œê±° (visualization_image ë“±)
            return None
        elif has_dlib and isinstance(obj, (dlib.rectangle, dlib.full_object_detection)):
            # dlib ê°ì²´ëŠ” ì œê±°
            return None
        elif isinstance(obj, (str, int, float, bool, type(None))):
            # JSON ê¸°ë³¸ íƒ€ì…
            return obj
        elif hasattr(obj, '__dict__') and not callable(obj):
            # ì¼ë°˜ ê°ì²´ëŠ” ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ ì‹œë„
            try:
                return str(obj)
            except:
                return None
        else:
            # ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì…ì€ ë¬¸ìì—´ë¡œ ë³€í™˜ ì‹œë„
            try:
                return str(obj)
            except:
                return None

    def _convert_to_tcp_spec_format(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """
        UnifiedFaceAnalyzer ê²°ê³¼ë¥¼ TCP_SPEC.md í˜•ì‹ìœ¼ë¡œ ë³€í™˜

        Args:
            result: UnifiedFaceAnalyzer ë¶„ì„ ê²°ê³¼

        Returns:
            TCP_SPEC.md ê·œê²©ì˜ JSON ë”•ì…”ë„ˆë¦¬
        """
        tcp_result = {}

        # Timestamp
        if 'metadata' in result and 'timestamp' in result['metadata']:
            tcp_result['timestamp'] = result['metadata']['timestamp']
        else:
            from datetime import datetime
            tcp_result['timestamp'] = datetime.now().isoformat()

        # Image path
        if 'metadata' in result and 'image_path' in result['metadata']:
            tcp_result['image_path'] = result['metadata']['image_path']
        else:
            tcp_result['image_path'] = ""

        # Hairstyle
        if 'hairstyle' in result and result['hairstyle'].get('classification'):
            hairstyle_name = result['hairstyle']['classification']
            tcp_result['hairstyle'] = self.HAIRSTYLE_ENUM.get(hairstyle_name, -1)
            tcp_result['hairstyle_name'] = hairstyle_name
        else:
            tcp_result['hairstyle'] = -1
            tcp_result['hairstyle_name'] = "Unknown"

        # Gender (from CLIP results)
        if 'hairstyle' in result and 'clip_results' in result['hairstyle']:
            clip = result['hairstyle']['clip_results']
            gender_name = clip.get('gender', 'Male')
            tcp_result['gender'] = self.GENDER_ENUM.get(gender_name, -1)
            tcp_result['gender_name'] = gender_name

            # Gender confidence (ë¬¸ìì—´ì„ floatë¡œ ë³€í™˜)
            gender_conf = clip.get('gender_confidence', '0.0')
            if isinstance(gender_conf, str):
                tcp_result['gender_confidence'] = float(gender_conf)
            else:
                tcp_result['gender_confidence'] = float(gender_conf)

            # Glasses
            has_glasses = 1 if clip.get('glasses') == "With Glasses" else 0
            tcp_result['has_glasses'] = has_glasses

            glasses_conf = clip.get('glasses_confidence', '0.0')
            if isinstance(glasses_conf, str):
                tcp_result['glasses_confidence'] = float(glasses_conf)
            else:
                tcp_result['glasses_confidence'] = float(glasses_conf)

            # Beard
            has_beard = 1 if clip.get('beard') == "With Beard" else 0
            tcp_result['has_beard'] = has_beard

            beard_conf = clip.get('beard_confidence', '0.0')
            if isinstance(beard_conf, str):
                tcp_result['beard_confidence'] = float(beard_conf)
            else:
                tcp_result['beard_confidence'] = float(beard_conf)
        else:
            tcp_result['gender'] = -1
            tcp_result['gender_name'] = "Unknown"
            tcp_result['gender_confidence'] = 0.0
            tcp_result['has_glasses'] = 0
            tcp_result['glasses_confidence'] = 0.0
            tcp_result['has_beard'] = 0
            tcp_result['beard_confidence'] = 0.0

        # Face Shape (from MediaPipe)
        if 'mediapipe' in result and 'face_shape_analysis' in result['mediapipe']:
            face_shape_name = result['mediapipe']['face_shape_analysis'].get('face_shape', 'oval')
            tcp_result['face_shape'] = self.FACE_SHAPE_ENUM.get(face_shape_name, -1)
            tcp_result['face_shape_name'] = face_shape_name
        else:
            tcp_result['face_shape'] = -1
            tcp_result['face_shape_name'] = "Unknown"

        # Eye Shape (from MediaPipe)
        if 'mediapipe' in result and 'eye_analysis' in result['mediapipe']:
            eye_shape_name = result['mediapipe']['eye_analysis'].get('overall_eye_shape', 'almond')
            tcp_result['eye_shape'] = self.EYE_SHAPE_ENUM.get(eye_shape_name, -1)
            tcp_result['eye_shape_name'] = eye_shape_name
        else:
            tcp_result['eye_shape'] = -1
            tcp_result['eye_shape_name'] = "Unknown"

        return tcp_result

    def send_json_result(self, client_socket: socket.socket, result: Dict[str, Any]) -> bool:
        """
        JSON ê²°ê³¼ë¥¼ í´ë¼ì´ì–¸íŠ¸ì— ì „ì†¡

        Protocol (No size header):
        - ì§ì ‘ JSON ë¬¸ìì—´ ì „ì†¡ (UTF-8)

        Args:
            client_socket: í´ë¼ì´ì–¸íŠ¸ ì†Œì¼“
            result: ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬

        Returns:
            ì „ì†¡ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # TCP_SPEC.md í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            logger.debug("Converting result to TCP_SPEC format...")
            tcp_result = self._convert_to_tcp_spec_format(result)
            logger.debug(f"Conversion complete. Keys: {list(tcp_result.keys())}")

            # JSON ì§ë ¬í™”
            logger.debug("Attempting JSON serialization...")
            json_str = json.dumps(tcp_result, ensure_ascii=False)
            json_bytes = json_str.encode('utf-8')
            logger.debug(f"JSON serialization successful: {len(json_bytes)} bytes")

            # JSON ë°ì´í„° ì „ì†¡ (4-byte size header ì—†ì´)
            client_socket.sendall(json_bytes)

            logger.info(f"JSON result sent: {len(json_bytes)} bytes (no size header)")
            return True

        except TypeError as e:
            logger.error(f"JSON serialization error: {e}")
            logger.debug(f"Result type: {type(result)}")
            if isinstance(result, dict):
                for key, value in result.items():
                    logger.debug(f"  {key}: {type(value)}")
            return False
        except Exception as e:
            logger.error(f"Error sending JSON result: {e}", exc_info=True)
            return False

    def handle_client(self, client_socket: socket.socket, client_address: tuple):
        """
        í´ë¼ì´ì–¸íŠ¸ ìš”ì²­ ì²˜ë¦¬

        Args:
            client_socket: í´ë¼ì´ì–¸íŠ¸ ì†Œì¼“
            client_address: í´ë¼ì´ì–¸íŠ¸ ì£¼ì†Œ
        """
        print(f"ğŸ”— í´ë¼ì´ì–¸íŠ¸ ì—°ê²°: {client_address[0]}:{client_address[1]}")
        logger.info(f"Client connected: {client_address}")

        try:
            while self.is_running:
                # 1. ì´ë¯¸ì§€ ìˆ˜ì‹ 
                print(f"\nğŸ“¥ ì´ë¯¸ì§€ ìˆ˜ì‹  ì¤‘...")
                image = self.receive_image(client_socket)

                if image is None:
                    print("âŒ ì´ë¯¸ì§€ ìˆ˜ì‹  ì‹¤íŒ¨")
                    break

                print(f"âœ… ì´ë¯¸ì§€ ìˆ˜ì‹  ì™„ë£Œ: {image.shape}")

                # 2. ì´ë¯¸ì§€ ë¶„ì„
                print("ğŸ” ì–¼êµ´ ë¶„ì„ ì¤‘...")
                start_time = time.time()

                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (UnifiedFaceAnalyzerê°€ íŒŒì¼ ê²½ë¡œë¥¼ ìš”êµ¬í•¨)
                import tempfile
                import os

                # í¬ë¡œìŠ¤ í”Œë«í¼ ì„ì‹œ íŒŒì¼ ìƒì„±
                temp_fd, temp_path = tempfile.mkstemp(suffix='.jpg', prefix='unreal_')
                os.close(temp_fd)  # íŒŒì¼ ë””ìŠ¤í¬ë¦½í„° ë‹«ê¸°

                logger.info(f"Saving image to temp file: {temp_path}")
                write_success = cv2.imwrite(temp_path, image)

                if not write_success:
                    logger.error(f"Failed to write image to {temp_path}")
                    print(f"âŒ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {temp_path}")
                    break

                logger.info(f"Image saved successfully, starting analysis...")
                result = self.analyzer.analyze_image(temp_path)
                logger.info(f"Analysis completed")

                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                try:
                    os.unlink(temp_path)
                except:
                    pass

                analysis_time = (time.time() - start_time) * 1000
                print(f"âœ… ë¶„ì„ ì™„ë£Œ: {analysis_time:.2f}ms")

                # 3. ê²°ê³¼ ìš”ì•½ ì¶œë ¥
                if result.get('success'):
                    if 'mediapipe' in result and result['mediapipe'].get('success'):
                        mp = result['mediapipe']
                        print(f"   ğŸ“ MediaPipe: {mp.get('landmarks_count', 0)} landmarks")
                        if 'eye_analysis' in mp:
                            print(f"   ğŸ‘ï¸  Eye: {mp['eye_analysis']['overall_eye_shape']}")
                        if 'face_shape_analysis' in mp:
                            print(f"   ğŸ˜Š Face: {mp['face_shape_analysis']['face_shape']}")

                    if 'hairstyle' in result:
                        hs = result['hairstyle']
                        print(f"   ğŸ’‡ Hairstyle: {hs.get('classification', 'Unknown')}")

                # 4. JSON ê²°ê³¼ ì „ì†¡
                print("ğŸ“¤ JSON ê²°ê³¼ ì „ì†¡ ì¤‘...")
                success = self.send_json_result(client_socket, result)

                if success:
                    print("âœ… ê²°ê³¼ ì „ì†¡ ì™„ë£Œ")
                else:
                    print("âŒ ê²°ê³¼ ì „ì†¡ ì‹¤íŒ¨")
                    break

        except Exception as e:
            logger.error(f"Error handling client: {e}", exc_info=True)
            print(f"âŒ í´ë¼ì´ì–¸íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

        finally:
            client_socket.close()
            print(f"ğŸ”Œ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ: {client_address[0]}:{client_address[1]}\n")
            logger.info(f"Client disconnected: {client_address}")

    def run(self):
        """ì„œë²„ ì‹¤í–‰ (ë©”ì¸ ë£¨í”„)"""
        if not self.is_running:
            self.start()

        try:
            while self.is_running:
                # í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŒ€ê¸°
                client_socket, client_address = self.server_socket.accept()

                # í´ë¼ì´ì–¸íŠ¸ ì²˜ë¦¬ (ë™ê¸° ë°©ì‹)
                self.handle_client(client_socket, client_address)

        except KeyboardInterrupt:
            print("\n\nâš ï¸  ì„œë²„ ì¢…ë£Œ ìš”ì²­ (Ctrl+C)")
        except Exception as e:
            logger.error(f"Server error: {e}", exc_info=True)
            print(f"\nâŒ ì„œë²„ ì˜¤ë¥˜: {e}")
        finally:
            self.stop()

    def __enter__(self):
        """Context manager ì§„ì…"""
        self.start()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager ì¢…ë£Œ"""
        self.stop()


def load_config(config_path: str = 'config.yaml') -> dict:
    """
    Config íŒŒì¼ ë¡œë“œ

    Args:
        config_path: config.yaml íŒŒì¼ ê²½ë¡œ

    Returns:
        ì„¤ì • ë”•ì…”ë„ˆë¦¬
    """
    import yaml
    import os

    if not os.path.exists(config_path):
        logger.warning(f"Config file not found: {config_path}, using defaults")
        return {
            'server': {
                'host': '0.0.0.0',
                'port': 5001,
                'max_connections': 5
            }
        }

    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        logger.info(f"Config loaded from {config_path}")
        return config
    except Exception as e:
        logger.error(f"Error loading config: {e}")
        return {
            'server': {
                'host': '0.0.0.0',
                'port': 5001,
                'max_connections': 5
            }
        }


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description='Unified Face Analysis TCP Server')
    parser.add_argument('--config', default='config.yaml', help='Config file path (default: config.yaml)')
    parser.add_argument('--host', default=None, help='Server host (overrides config)')
    parser.add_argument('--port', type=int, default=None, help='Server port (overrides config)')
    parser.add_argument('--max-connections', type=int, default=None, help='Max connections (overrides config)')
    parser.add_argument('--env', default='production', choices=['development', 'production', 'restricted'],
                        help='Environment (default: production)')

    args = parser.parse_args()

    # Config íŒŒì¼ ë¡œë“œ
    config = load_config(args.config)

    # í™˜ê²½ë³„ ì„¤ì • ì ìš©
    if 'environments' in config and args.env in config['environments']:
        env_config = config['environments'][args.env]
        server_config = {**config.get('server', {}), **env_config}
    else:
        server_config = config.get('server', {})

    # ëª…ë ¹ì¤„ ì¸ìê°€ ìš°ì„ ìˆœìœ„ (config ë®ì–´ì“°ê¸°)
    host = args.host if args.host is not None else server_config.get('host', '0.0.0.0')
    port = args.port if args.port is not None else server_config.get('port', 5001)
    max_connections = args.max_connections if args.max_connections is not None else server_config.get('max_connections', 5)

    print(f"ğŸ”§ Server Configuration:")
    print(f"   Environment: {args.env}")
    print(f"   Host: {host}")
    print(f"   Port: {port}")
    print(f"   Max Connections: {max_connections}")

    # ì„œë²„ ìƒì„± ë° ì‹¤í–‰
    server = UnifiedFaceAnalysisTCPServer(
        host=host,
        port=port,
        max_connections=max_connections
    )

    server.run()


if __name__ == '__main__':
    main()
