"""
Unified Face Analyzer
MediaPipe + BiSeNet + CLIP + dlib í†µí•© ì–¼êµ´ ë¶„ì„ ì‹œìŠ¤í…œ
"""

import time
import cv2
import numpy as np
from typing import Dict, Any, Optional
from pathlib import Path

from core.mediapipe import FaceDetector as MediaPipeDetector, FaceAnalyzer
from core.hairstyle_analyzer import HairstyleAnalyzer
from models.landmark_models import DetectionResult, FaceGeometry, DetailedFaceAnalysis
from utils import get_config, get_logger

logger = get_logger(__name__)


class UnifiedFaceAnalyzer:
    """
    í†µí•© ì–¼êµ´ ë¶„ì„ ì‹œìŠ¤í…œ

    Features:
    - MediaPipe: 468ê°œ ëœë“œë§ˆí¬ + ì–¼êµ´ ê°ë„ (pitch, yaw, roll)
    - HairstyleAnalyzer: BiSeNet + CLIP + dlib 68ì  ê¸°ë°˜ í—¤ì–´ìŠ¤íƒ€ì¼ ë¶„ì„
    - í†µí•© ê²°ê³¼ JSON ìƒì„±
    """

    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.config = get_config()

        # í†µí•© ë¶„ì„ ì„¤ì •
        self.unified_config = self.config.unified_analysis

        # MediaPipe ì´ˆê¸°í™” (ì„ íƒì )
        self.mediapipe_detector = None
        self.face_analyzer = None
        if self.unified_config.enable_mediapipe:
            try:
                self.mediapipe_detector = MediaPipeDetector()
                self.face_analyzer = FaceAnalyzer()
                logger.info("MediaPipe detector and FaceAnalyzer initialized")
            except Exception as e:
                logger.warning(f"Failed to initialize MediaPipe: {e}")

        # HairstyleAnalyzer ì´ˆê¸°í™” (ì„ íƒì )
        self.hairstyle_analyzer = None
        if self.unified_config.enable_hairstyle:
            try:
                self.hairstyle_analyzer = HairstyleAnalyzer()
                logger.info("Hairstyle analyzer initialized")
            except Exception as e:
                logger.warning(f"Failed to initialize HairstyleAnalyzer: {e}")

        logger.info("UnifiedFaceAnalyzer initialized successfully")

    def analyze_image(self, image_path: str) -> Dict[str, Any]:
        """
        í†µí•© ì´ë¯¸ì§€ ë¶„ì„

        Args:
            image_path: ë¶„ì„í•  ì´ë¯¸ì§€ ê²½ë¡œ

        Returns:
            í†µí•© ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬:
            {
                'success': bool,
                'mediapipe': {
                    'success': bool,
                    'landmarks_count': int,
                    'face_geometry': {
                        'pitch': float,
                        'yaw': float,
                        'roll': float,
                        'face_width': float,
                        'face_height': float
                    },
                    'processing_time_ms': float
                },
                'hairstyle': {
                    'classification': str,
                    'clip_results': {...},
                    'geometric_analysis': {...}
                },
                'metadata': {
                    'image_path': str,
                    'total_processing_time_ms': float,
                    'timestamp': str,
                    'enabled_modules': List[str]
                }
            }
        """
        start_time = time.time()

        # ì´ë¯¸ì§€ ë¡œë“œ
        if not Path(image_path).exists():
            logger.error(f"Image not found: {image_path}")
            return {
                'success': False,
                'error': f'Image not found: {image_path}'
            }

        image = cv2.imread(image_path)
        if image is None:
            logger.error(f"Failed to load image: {image_path}")
            return {
                'success': False,
                'error': f'Failed to load image: {image_path}'
            }

        result = {
            'success': True,
            'metadata': {
                'image_path': image_path,
                'enabled_modules': []
            }
        }

        # MediaPipe ë¶„ì„
        if self.mediapipe_detector and self.unified_config.enable_mediapipe:
            try:
                mediapipe_result = self._analyze_with_mediapipe(image)
                result['mediapipe'] = mediapipe_result
                result['metadata']['enabled_modules'].append('mediapipe')
                logger.info(f"MediaPipe analysis completed: {mediapipe_result['success']}")
            except Exception as e:
                logger.error(f"MediaPipe analysis failed: {e}", exc_info=True)
                result['mediapipe'] = {'success': False, 'error': str(e)}

        # Hairstyle ë¶„ì„
        if self.hairstyle_analyzer and self.unified_config.enable_hairstyle:
            try:
                hairstyle_result, viz_image = self.hairstyle_analyzer.analyze_image(image_path)
                result['hairstyle'] = hairstyle_result
                result['visualization_image'] = viz_image  # numpy array
                result['metadata']['enabled_modules'].append('hairstyle')
                logger.info(f"Hairstyle analysis completed: {hairstyle_result.get('classification', 'Unknown')}")
            except Exception as e:
                logger.error(f"Hairstyle analysis failed: {e}", exc_info=True)
                result['hairstyle'] = {'success': False, 'error': str(e)}

        # ë©”íƒ€ë°ì´í„° ì™„ì„±
        total_time = (time.time() - start_time) * 1000
        result['metadata']['total_processing_time_ms'] = round(total_time, 2)
        result['metadata']['timestamp'] = time.strftime("%Y-%m-%dT%H:%M:%S")

        logger.info(f"Unified analysis completed in {total_time:.2f}ms")

        return result

    def _analyze_with_mediapipe(self, image: np.ndarray) -> Dict[str, Any]:
        """
        MediaPipeë¡œ ì–¼êµ´ ë¶„ì„ (ëœë“œë§ˆí¬ + ì–¼êµ´í˜• + ëˆˆê¼¬ë¦¬)

        Args:
            image: BGR ì´ë¯¸ì§€ (numpy array)

        Returns:
            MediaPipe ë¶„ì„ ê²°ê³¼
        """
        # ì–¼êµ´ ê²€ì¶œ
        detection_result: DetectionResult = self.mediapipe_detector.detect(image)

        if not detection_result.success:
            return {
                'success': False,
                'landmarks_count': 0,
                'processing_time_ms': detection_result.processing_time
            }

        # ì–¼êµ´ ê¸°í•˜í•™ ê³„ì‚°
        face_geometry: FaceGeometry = self.mediapipe_detector.calculate_geometry(
            detection_result.landmarks
        )

        result = {
            'success': True,
            'landmarks_count': len(detection_result.landmarks),
            'confidence': detection_result.confidence,
            'face_geometry': {
                'pitch': round(face_geometry.pitch, 2),
                'yaw': round(face_geometry.yaw, 2),
                'roll': round(face_geometry.roll, 2),
                'face_width': round(face_geometry.face_width, 4),
                'face_height': round(face_geometry.face_height, 4)
            },
            'processing_time_ms': round(detection_result.processing_time, 2)
        }

        # FaceAnalyzerë¡œ ì–¼êµ´í˜• + ëˆˆê¼¬ë¦¬ ë¶„ì„
        if self.face_analyzer:
            try:
                detailed_analysis: DetailedFaceAnalysis = self.face_analyzer.get_detailed_analysis(
                    detection_result.landmarks,
                    roll_angle=face_geometry.roll,
                    yaw_angle=face_geometry.yaw
                )

                # ëˆˆ í˜•íƒœ ë¶„ì„ ê²°ê³¼ ì¶”ê°€
                if detailed_analysis.eye_analysis:
                    result['eye_analysis'] = detailed_analysis.eye_analysis.to_dict()

                # ì–¼êµ´í˜• ë¶„ì„ ê²°ê³¼ ì¶”ê°€
                if detailed_analysis.face_shape_analysis:
                    result['face_shape_analysis'] = detailed_analysis.face_shape_analysis.to_dict()

            except Exception as e:
                logger.warning(f"FaceAnalyzer failed: {e}")

        return result

    def get_compact_result(self, full_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        ì••ì¶•ëœ ê²°ê³¼ ë°˜í™˜ (TCP ì „ì†¡ìš©)

        Args:
            full_result: analyze_image()ì˜ ì „ì²´ ê²°ê³¼

        Returns:
            ì••ì¶•ëœ ê²°ê³¼ (í•µì‹¬ ì •ë³´ë§Œ)
        """
        compact = {
            'timestamp': full_result['metadata']['timestamp'],
            'success': full_result['success']
        }

        # MediaPipe í•µì‹¬ ì •ë³´
        if 'mediapipe' in full_result and full_result['mediapipe'].get('success'):
            mp = full_result['mediapipe']
            compact['face_geometry'] = mp['face_geometry']

        # Hairstyle í•µì‹¬ ì •ë³´
        if 'hairstyle' in full_result:
            hs = full_result['hairstyle']
            compact['hairstyle'] = {
                'classification': hs.get('classification', 'Unknown')
            }

            if 'clip_results' in hs:
                clip = hs['clip_results']
                compact['hairstyle'].update({
                    'gender': clip.get('gender', 'Unknown'),
                    'glasses': clip.get('glasses', 'Unknown'),
                    'beard': clip.get('beard', 'Unknown')
                })

        return compact

    def __repr__(self):
        enabled = self.config.unified_analysis
        return (
            f"UnifiedFaceAnalyzer("
            f"mediapipe={enabled.enable_mediapipe}, "
            f"hairstyle={enabled.enable_hairstyle})"
        )


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    import sys

    if len(sys.argv) < 2:
        print("Usage: python unified_analyzer.py <image_path>")
        sys.exit(1)

    image_path = sys.argv[1]

    analyzer = UnifiedFaceAnalyzer()
    print(f"\n{analyzer}\n")

    result = analyzer.analyze_image(image_path)

    print("=== Unified Analysis Result ===\n")

    if result['success']:
        # MediaPipe ê²°ê³¼
        if 'mediapipe' in result and result['mediapipe'].get('success'):
            mp = result['mediapipe']
            print("ğŸ“ MediaPipe Analysis:")
            print(f"  Landmarks: {mp['landmarks_count']}")
            print(f"  Face Geometry:")
            geo = mp['face_geometry']
            print(f"    Pitch: {geo['pitch']}Â°")
            print(f"    Yaw: {geo['yaw']}Â°")
            print(f"    Roll: {geo['roll']}Â°")
            print(f"  Processing Time: {mp['processing_time_ms']}ms\n")

        # Hairstyle ê²°ê³¼
        if 'hairstyle' in result:
            hs = result['hairstyle']
            print("ğŸ’‡ Hairstyle Analysis:")
            print(f"  Classification: {hs.get('classification', 'Unknown')}")

            if 'clip_results' in hs:
                clip = hs['clip_results']
                print(f"  Gender: {clip.get('gender', 'Unknown')}")
                print(f"  Glasses: {clip.get('glasses', 'Unknown')}")
                print(f"  Beard: {clip.get('beard', 'Unknown')}\n")

        # ë©”íƒ€ë°ì´í„°
        meta = result['metadata']
        print(f"â±ï¸  Total Time: {meta['total_processing_time_ms']}ms")
        print(f"ğŸ“¦ Enabled Modules: {', '.join(meta['enabled_modules'])}")
    else:
        print(f"âŒ Analysis failed: {result.get('error', 'Unknown error')}")
